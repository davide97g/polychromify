{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comparison",
      "provenance": [],
      "collapsed_sections": [
        "bMDlfkNTtRoR",
        "_DE2vA3ktUTd",
        "kPkoZLcLtZeY",
        "cXU4_K3-tl4m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tDLWRIur5Ki"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from IPython import embed\n",
        "from PIL import Image\n",
        "from skimage import color\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import random\n",
        "\n",
        "import os\n",
        "\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0W2dBz2HJ3X"
      },
      "source": [
        "dataset_path = \"drive/MyDrive/tiny-imagenet-200/\"\n",
        "models_path = 'drive/MyDrive/Università/Magistrale/VCS/models/'\n",
        "sample_path = \"drive/MyDrive/Università/Magistrale/VCS/sample/\"\n",
        "\n",
        "SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q28t99PEF4Gy"
      },
      "source": [
        "X_test = np.load(dataset_path+'x_test.npy')\n",
        "Y_test = np.load(dataset_path+'y_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL-9JtSgF8kc"
      },
      "source": [
        "def PSNR(y_true,y_pred):\n",
        "  return tf.image.psnr(y_true, y_pred, max_val=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMDlfkNTtRoR"
      },
      "source": [
        "## Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7tITIONsAG_"
      },
      "source": [
        "class BaseColor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseColor, self).__init__()\n",
        "\n",
        "        self.l_cent = 50.\n",
        "        self.l_norm = 100.\n",
        "        self.ab_norm = 110.\n",
        "\n",
        "    def normalize_l(self, in_l):\n",
        "        return (in_l-self.l_cent)/self.l_norm\n",
        "\n",
        "    def unnormalize_l(self, in_l):\n",
        "        return in_l*self.l_norm + self.l_cent\n",
        "\n",
        "    def normalize_ab(self, in_ab):\n",
        "        return in_ab/self.ab_norm\n",
        "\n",
        "    def unnormalize_ab(self, in_ab):\n",
        "        return in_ab*self.ab_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkfVG1W8sFHh"
      },
      "source": [
        "def load_img(img_path):\n",
        "    out_np = np.asarray(Image.open(img_path))\n",
        "    if(out_np.ndim==2):\n",
        "        out_np = np.tile(out_np[:,:,None],3)\n",
        "    return out_np\n",
        "\n",
        "def resize_img(img, HW=(256,256), resample=3):\n",
        "    return np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))\n",
        "\n",
        "def preprocess_img(img_rgb_orig, HW=(256,256), resample=3):\n",
        "    # return original size L and resized L as torch Tensors\n",
        "    img_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)\n",
        "\n",
        "    img_lab_orig = color.rgb2lab(img_rgb_orig)\n",
        "    img_lab_rs = color.rgb2lab(img_rgb_rs)\n",
        "\n",
        "    img_l_orig = img_lab_orig[:,:,0]\n",
        "    img_l_rs = img_lab_rs[:,:,0]\n",
        "\n",
        "    tens_orig_l = torch.Tensor(img_l_orig)[None,None,:,:]\n",
        "    tens_rs_l = torch.Tensor(img_l_rs)[None,None,:,:]\n",
        "\n",
        "    return (tens_orig_l, tens_rs_l)\n",
        "\n",
        "def postprocess_tens(tens_orig_l, out_ab, mode='bilinear'):\n",
        "    # tens_orig_l 1 x 1 x H_orig x W_orig\n",
        "    # out_ab 1 x 2 x H x W\n",
        "\n",
        "    HW_orig = tens_orig_l.shape[2:]\n",
        "    HW = out_ab.shape[2:]\n",
        "\n",
        "    # call resize function if needed\n",
        "    if(HW_orig[0]!=HW[0] or HW_orig[1]!=HW[1]):\n",
        "        out_ab_orig = F.interpolate(out_ab, size=HW_orig, mode='bilinear')\n",
        "    else:\n",
        "        out_ab_orig = out_ab\n",
        "\n",
        "    out_lab_orig = torch.cat((tens_orig_l, out_ab_orig), dim=1)\n",
        "    return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DE2vA3ktUTd"
      },
      "source": [
        "## ECCV16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Eh4dOAsFmz"
      },
      "source": [
        "class ECCVGenerator(BaseColor):\n",
        "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
        "        super(ECCVGenerator, self).__init__()\n",
        "\n",
        "        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[norm_layer(64),]\n",
        "\n",
        "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[norm_layer(128),]\n",
        "\n",
        "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[norm_layer(256),]\n",
        "\n",
        "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[norm_layer(512),]\n",
        "\n",
        "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[norm_layer(512),]\n",
        "\n",
        "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[norm_layer(512),]\n",
        "\n",
        "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[norm_layer(512),]\n",
        "\n",
        "        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "\n",
        "        model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]\n",
        "\n",
        "        self.model1 = nn.Sequential(*model1)\n",
        "        self.model2 = nn.Sequential(*model2)\n",
        "        self.model3 = nn.Sequential(*model3)\n",
        "        self.model4 = nn.Sequential(*model4)\n",
        "        self.model5 = nn.Sequential(*model5)\n",
        "        self.model6 = nn.Sequential(*model6)\n",
        "        self.model7 = nn.Sequential(*model7)\n",
        "        self.model8 = nn.Sequential(*model8)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
        "\n",
        "    def forward(self, input_l):\n",
        "        conv1_2 = self.model1(self.normalize_l(input_l))\n",
        "        conv2_2 = self.model2(conv1_2)\n",
        "        conv3_3 = self.model3(conv2_2)\n",
        "        conv4_3 = self.model4(conv3_3)\n",
        "        conv5_3 = self.model5(conv4_3)\n",
        "        conv6_3 = self.model6(conv5_3)\n",
        "        conv7_3 = self.model7(conv6_3)\n",
        "        conv8_3 = self.model8(conv7_3)\n",
        "        out_reg = self.model_out(self.softmax(conv8_3))\n",
        "\n",
        "        return self.unnormalize_ab(self.upsample4(out_reg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "555Fb1fnsHVT"
      },
      "source": [
        "def eccv16(pretrained=True):\n",
        "    model = ECCVGenerator()\n",
        "    if(pretrained):\n",
        "        import torch.utils.model_zoo as model_zoo\n",
        "        model.load_state_dict(\n",
        "            model_zoo.load_url('https://colorizers.s3.us-east-2.amazonaws.com/colorization_release_v2-9b330a0b.pth',\n",
        "                               map_location='cpu',\n",
        "                               check_hash=True)\n",
        "        )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzuy0hg9sJZK"
      },
      "source": [
        "colorizer_eccv16 = eccv16(pretrained=True).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-cxABX4Q5HA"
      },
      "source": [
        "summary(colorizer_eccv16, (1, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPkoZLcLtZeY"
      },
      "source": [
        "## SIGGRAPH17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-YCP37rspp6"
      },
      "source": [
        "class SIGGRAPHGenerator(BaseColor):\n",
        "    def __init__(self, norm_layer=nn.BatchNorm2d, classes=529):\n",
        "        super(SIGGRAPHGenerator, self).__init__()\n",
        "\n",
        "        # Conv1\n",
        "        model1=[nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model1+=[nn.ReLU(True),]\n",
        "        model1+=[norm_layer(64),]\n",
        "        # add a subsampling operation\n",
        "\n",
        "        # Conv2\n",
        "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model2+=[nn.ReLU(True),]\n",
        "        model2+=[norm_layer(128),]\n",
        "        # add a subsampling layer operation\n",
        "\n",
        "        # Conv3\n",
        "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model3+=[nn.ReLU(True),]\n",
        "        model3+=[norm_layer(256),]\n",
        "        # add a subsampling layer operation\n",
        "\n",
        "        # Conv4\n",
        "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model4+=[nn.ReLU(True),]\n",
        "        model4+=[norm_layer(512),]\n",
        "\n",
        "        # Conv5\n",
        "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model5+=[nn.ReLU(True),]\n",
        "        model5+=[norm_layer(512),]\n",
        "\n",
        "        # Conv6\n",
        "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
        "        model6+=[nn.ReLU(True),]\n",
        "        model6+=[norm_layer(512),]\n",
        "\n",
        "        # Conv7\n",
        "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model7+=[nn.ReLU(True),]\n",
        "        model7+=[norm_layer(512),]\n",
        "\n",
        "        # Conv7\n",
        "        model8up=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True)]\n",
        "        model3short8=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "\n",
        "        model8=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model8+=[nn.ReLU(True),]\n",
        "        model8+=[norm_layer(256),]\n",
        "\n",
        "        # Conv9\n",
        "        model9up=[nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=True),]\n",
        "        model2short9=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        # add the two feature maps above        \n",
        "\n",
        "        model9=[nn.ReLU(True),]\n",
        "        model9+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        model9+=[nn.ReLU(True),]\n",
        "        model9+=[norm_layer(128),]\n",
        "\n",
        "        # Conv10\n",
        "        model10up=[nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=True),]\n",
        "        model1short10=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
        "        # add the two feature maps above\n",
        "\n",
        "        model10=[nn.ReLU(True),]\n",
        "        model10+=[nn.Conv2d(128, 128, kernel_size=3, dilation=1, stride=1, padding=1, bias=True),]\n",
        "        model10+=[nn.LeakyReLU(negative_slope=.2),]\n",
        "\n",
        "        # classification output\n",
        "        model_class=[nn.Conv2d(256, classes, kernel_size=1, padding=0, dilation=1, stride=1, bias=True),]\n",
        "\n",
        "        # regression output\n",
        "        model_out=[nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=True),]\n",
        "        model_out+=[nn.Tanh()]\n",
        "\n",
        "        self.model1 = nn.Sequential(*model1)\n",
        "        self.model2 = nn.Sequential(*model2)\n",
        "        self.model3 = nn.Sequential(*model3)\n",
        "        self.model4 = nn.Sequential(*model4)\n",
        "        self.model5 = nn.Sequential(*model5)\n",
        "        self.model6 = nn.Sequential(*model6)\n",
        "        self.model7 = nn.Sequential(*model7)\n",
        "        self.model8up = nn.Sequential(*model8up)\n",
        "        self.model8 = nn.Sequential(*model8)\n",
        "        self.model9up = nn.Sequential(*model9up)\n",
        "        self.model9 = nn.Sequential(*model9)\n",
        "        self.model10up = nn.Sequential(*model10up)\n",
        "        self.model10 = nn.Sequential(*model10)\n",
        "        self.model3short8 = nn.Sequential(*model3short8)\n",
        "        self.model2short9 = nn.Sequential(*model2short9)\n",
        "        self.model1short10 = nn.Sequential(*model1short10)\n",
        "\n",
        "        self.model_class = nn.Sequential(*model_class)\n",
        "        self.model_out = nn.Sequential(*model_out)\n",
        "\n",
        "        self.upsample4 = nn.Sequential(*[nn.Upsample(scale_factor=4, mode='bilinear'),])\n",
        "        self.softmax = nn.Sequential(*[nn.Softmax(dim=1),])\n",
        "\n",
        "    def forward(self, input_A, input_B=None, mask_B=None):\n",
        "        if(input_B is None):\n",
        "            input_B = torch.cat((input_A*0, input_A*0), dim=1)\n",
        "        if(mask_B is None):\n",
        "            mask_B = input_A*0\n",
        "\n",
        "        conv1_2 = self.model1(torch.cat((self.normalize_l(input_A),self.normalize_ab(input_B),mask_B),dim=1))\n",
        "        conv2_2 = self.model2(conv1_2[:,:,::2,::2])\n",
        "        conv3_3 = self.model3(conv2_2[:,:,::2,::2])\n",
        "        conv4_3 = self.model4(conv3_3[:,:,::2,::2])\n",
        "        conv5_3 = self.model5(conv4_3)\n",
        "        conv6_3 = self.model6(conv5_3)\n",
        "        conv7_3 = self.model7(conv6_3)\n",
        "\n",
        "        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3)\n",
        "        conv8_3 = self.model8(conv8_up)\n",
        "        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)\n",
        "        conv9_3 = self.model9(conv9_up)\n",
        "        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)\n",
        "        conv10_2 = self.model10(conv10_up)\n",
        "        out_reg = self.model_out(conv10_2)\n",
        "\n",
        "        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)\n",
        "        conv9_3 = self.model9(conv9_up)\n",
        "        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)\n",
        "        conv10_2 = self.model10(conv10_up)\n",
        "        out_reg = self.model_out(conv10_2)\n",
        "\n",
        "        return self.unnormalize_ab(out_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0OljXbsso_"
      },
      "source": [
        "def siggraph17(pretrained=True):\n",
        "    model = SIGGRAPHGenerator()\n",
        "    if(pretrained):\n",
        "        import torch.utils.model_zoo as model_zoo\n",
        "        model.load_state_dict(model_zoo.load_url('https://colorizers.s3.us-east-2.amazonaws.com/siggraph17-df00044c.pth',map_location='cpu',check_hash=True))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg7GERVPsuWz"
      },
      "source": [
        "colorizer_siggraph17 = siggraph17(pretrained=True).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xUipMxfQl0d"
      },
      "source": [
        "summary(colorizer_siggraph17, (1, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXU4_K3-tl4m"
      },
      "source": [
        "## Test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUQpv_Oy42O8"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALtmokb9tzoh"
      },
      "source": [
        "ECCV16_SSIM = 0\n",
        "ECCV16_PSNR = 0\n",
        "SIGGRAPH17_SSIM = 0\n",
        "SIGGRAPH17_PSNR = 0\n",
        "\n",
        "size = len(X_test)\n",
        "for i in tqdm(range(len(X_test[:size]))):   \n",
        "\n",
        "    # image reconstruction\n",
        "    L = X_test[i]\n",
        "    AB = Y_test[i]\n",
        "    \n",
        "    img = np.zeros((SIZE, SIZE, 3))\n",
        "    img[:,:,0] = L[:,:,0]\n",
        "    img[:,:,1:] = AB*128\n",
        "    img = lab2rgb(img)\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # preprocessing\n",
        "    (tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(64,64))\n",
        "\n",
        "    img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))\n",
        "    \n",
        "    # colorization\n",
        "    eccv16_colorized = colorizer_eccv16(tens_l_rs).cpu()\n",
        "    siggraph17_colorized = colorizer_siggraph17(tens_l_rs).cpu()\n",
        "\n",
        "    # postprocessing\n",
        "    out_img_eccv16 = postprocess_tens(tens_l_orig, eccv16_colorized)\n",
        "    out_img_siggraph17 = postprocess_tens(tens_l_orig, siggraph17_colorized)\n",
        "\n",
        "    # metrics computation\n",
        "    \n",
        "    img_or = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    im1 = tf.image.convert_image_dtype(out_img_eccv16, tf.float32)\n",
        "    im2 = tf.image.convert_image_dtype(out_img_siggraph17, tf.float32)\n",
        "\n",
        "    ssim1 = tf.image.ssim(img_or, im1, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    ssim2 = tf.image.ssim(img_or, im2, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    \n",
        "    psnr1 = PSNR(img_or,im1)\n",
        "    psnr2 = PSNR(img_or,im2)\n",
        "    \n",
        "    ECCV16_SSIM += ssim1\n",
        "    SIGGRAPH17_SSIM += ssim2\n",
        "\n",
        "    ECCV16_PSNR += psnr1\n",
        "    SIGGRAPH17_PSNR += psnr2\n",
        "\n",
        "print(f\"ECCV16 --> SSIM {ECCV16_SSIM/size} - PSNR {ECCV16_PSNR/size}\")\n",
        "print(f\"SIGGRAPH17 --> SSIM {SIGGRAPH17_SSIM/size} - PSNR {SIGGRAPH17_PSNR/size}\")\n",
        "# ECCV16 --> SSIM 0.9230453372001648 - PSNR 22.14032745361328\n",
        "# SIGGRAPH17 --> SSIM 0.9334288239479065 - PSNR 23.900009155273438"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTQpEeOi6Ozz"
      },
      "source": [
        "## Colorization comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEBgCVYpNk9p"
      },
      "source": [
        "polychromify = tf.keras.models.load_model(models_path+\"Polychromify\", custom_objects={'PSNR':PSNR})\n",
        "polychromifyA = tf.keras.models.load_model(models_path+\"Polychromify_A\", custom_objects={'PSNR':PSNR})\n",
        "polychromifyB = tf.keras.models.load_model(models_path+\"Polychromify_B\", custom_objects={'PSNR':PSNR})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X3uV7qvFp4r"
      },
      "source": [
        "outputs = []\n",
        "indexes = [3,4,18,8167,691,6956]\n",
        "left = 6-len(indexes)\n",
        "for i in range(left):\n",
        "  indexes.append(round(random.random()*len(X_test)))\n",
        "\n",
        "size = len(indexes)\n",
        "print(indexes)\n",
        "\n",
        "for i in indexes:       \n",
        "\n",
        "    # image merging\n",
        "    L = X_test[i]\n",
        "    AB = Y_test[i]\n",
        "    x = X_test[i]\n",
        "    \n",
        "    img = np.zeros((SIZE, SIZE, 3))\n",
        "    img[:,:,0] = L[:,:,0]\n",
        "    img[:,:,1:] = AB*128\n",
        "    img = lab2rgb(img)\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # preprocessing\n",
        "    (tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(64,64))\n",
        "    img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))\n",
        "    \n",
        "    # colorization\n",
        "    eccv16_colorized = colorizer_eccv16(tens_l_rs).cpu()\n",
        "    siggraph17_colorized = colorizer_siggraph17(tens_l_rs).cpu()    \n",
        "\n",
        "    img_color = np.array([x], dtype=float)\n",
        "\n",
        "    # polychromify    \n",
        "    output = polychromify.predict(img_color)\n",
        "    result = np.zeros((SIZE, SIZE, 3))\n",
        "    result[:,:,0] = x[:,:,0]\n",
        "    result[:,:,1:] = output[0]*128\n",
        "    out_img_polychromify = lab2rgb(result)\n",
        "\n",
        "    # polychromifyAB    \n",
        "    outputA = polychromifyA.predict(img_color)\n",
        "    outputB = polychromifyB.predict(img_color)\n",
        "    result = np.zeros((SIZE, SIZE, 3))\n",
        "    result[:,:,0] = x[:,:,0]\n",
        "    result[:,:,1] = outputA[0][:,:,0]*128\n",
        "    result[:,:,2] = outputB[0][:,:,0]*128\n",
        "    out_img_polychromifyAB = lab2rgb(result)\n",
        "\n",
        "    ##### ONLY FOR ECCV16 & SIGGRAPH17 #####\n",
        "\n",
        "    # postprocessing\n",
        "    out_img_eccv16 = postprocess_tens(tens_l_orig, eccv16_colorized)\n",
        "    out_img_siggraph17 = postprocess_tens(tens_l_orig, siggraph17_colorized)\n",
        "    # resize\n",
        "    out_img_eccv16 =  resize(out_img_eccv16, (SIZE,SIZE))\n",
        "    out_img_siggraph17 = resize(out_img_siggraph17, (SIZE,SIZE))\n",
        "\n",
        "    ### metrics computation ###\n",
        "\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    im_ECCV16 = tf.image.convert_image_dtype(out_img_eccv16, tf.float32)\n",
        "    im_SIGGRAPH17 = tf.image.convert_image_dtype(out_img_siggraph17, tf.float32)\n",
        "    im_POLY = tf.image.convert_image_dtype(out_img_polychromify, tf.float32)\n",
        "    im_POLYAB = tf.image.convert_image_dtype(out_img_polychromifyAB, tf.float32)\n",
        "\n",
        "    ssim_ECCV16 = tf.image.ssim(img, im_ECCV16, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    ssim_SIGGRAPH17 = tf.image.ssim(img, im_SIGGRAPH17, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    ssim_POLY = tf.image.ssim(img, im_POLY, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    ssim_POLYAB = tf.image.ssim(img, im_POLYAB, max_val=1.0, filter_size=11,\n",
        "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "    \n",
        "    psnr_ECCV16 = PSNR(img,im_ECCV16)\n",
        "    psnr_SIGGRAPH17 = PSNR(img,im_SIGGRAPH17)\n",
        "    psnr_POLY = PSNR(img,im_POLY)\n",
        "    psnr_POLYAB = PSNR(img,im_POLYAB)\n",
        "\n",
        "    ######################################################################## todo: save these metrics\n",
        "    # print(f\"ECCV16 --> SSIM {ssim_ECCV16} - PSNR {psnr_ECCV16}\")\n",
        "    # print(f\"SIGGRAPH17 --> SSIM {ssim_SIGGRAPH17} - PSNR {psnr_SIGGRAPH17}\")\n",
        "    # print(f\"POLY --> SSIM {ssim_POLY} - PSNR {psnr_POLY}\")\n",
        "    # print(f\"POLYAB --> SSIM {ssim_POLYAB} - PSNR {psnr_POLYAB}\")\n",
        "\n",
        "    outputs.append(img_bw)\n",
        "    outputs.append(out_img_eccv16)\n",
        "    outputs.append(out_img_siggraph17)\n",
        "    outputs.append(out_img_polychromify)\n",
        "    outputs.append(out_img_polychromifyAB)    \n",
        "    outputs.append(img)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY_otjGIRKDw"
      },
      "source": [
        "titles = [\"Input\",\"ECCV16\",\"SIGGRAPH17\",\"Polychromify\",\"PolychromifyAB\",\"Original\"]\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(size,len(titles)), axes_pad=0)\n",
        "\n",
        "counter = 0\n",
        "for ax, im in zip(grid, outputs):    \n",
        "    ax.imshow(im)\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])        \n",
        "    if counter < len(titles):\n",
        "      ax.set_title(titles[counter])    \n",
        "    counter+=1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}