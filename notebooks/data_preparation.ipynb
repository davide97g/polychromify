{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f4516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave, imshow\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86175d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/'\n",
    "dataset = \"tiny-imagenet-200/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eab9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 64 # this is the target size of the entire process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9b9ebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 1 classes.\n",
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"train/\", \n",
    "                                          target_size=(SIZE, SIZE), \n",
    "                                          class_mode=None)\n",
    "valid_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"val/\", \n",
    "                                          target_size=(SIZE, SIZE), \n",
    "                                          class_mode=None)\n",
    "test_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"test/\", \n",
    "                                          target_size=(SIZE, SIZE), \n",
    "                                          class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be729e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from RGB to Lab space\n",
    "\"\"\"\n",
    "by iterating on each image, we convert the RGB to Lab. \n",
    "Think of LAB image as a grey image in L channel and all color info stored in A and B channels. \n",
    "The input to the network will be the L channel, so I assign L channel to X vector. \n",
    "And assign A and B to Y.\n",
    "\"\"\"\n",
    "\n",
    "def convert_dataset(gen):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(gen))):\n",
    "        for img in gen[i]:\n",
    "            lab = rgb2lab(img)\n",
    "            X.append(lab[:,:,0]) \n",
    "            Y.append(lab[:,:,1:] / 128)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    X = X.reshape(X.shape+(1,))\n",
    "    print(X.shape, Y.shape)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46b61c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [38:11<00:00,  1.36it/s]\n",
      "  0%|                                                                                          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 64, 1) (100000, 64, 64, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [01:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 1) (10000, 64, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train = convert_dataset(train_gen)\n",
    "X_valid,Y_valid = convert_dataset(valid_gen)\n",
    "# X_test,Y_test = convert_dataset(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "224bed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../preprocessed/'+dataset+'x_train.npy', X_train)\n",
    "np.save('../preprocessed/'+dataset+'y_train.npy', Y_train)\n",
    "\n",
    "np.save('../preprocessed/'+dataset+'x_valid.npy', X_valid)\n",
    "np.save('../preprocessed/'+dataset+'y_valid.npy', Y_valid)\n",
    "\n",
    "# np.save('../preprocessed/'+dataset+'x_test.npy', X_test)\n",
    "# np.save('../preprocessed/'+dataset+'y_test.npy', Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
