{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data-preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg2kQ3MP1Jjn"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb0TdSNq1WS5"
      },
      "source": [
        "path = '../dataset/'\n",
        "dataset = \"tiny-imagenet-200/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKtvqVq11X3U"
      },
      "source": [
        "SIZE = 64 # this is the target size of the entire process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Sz5D9t1Zep"
      },
      "source": [
        "# create 3 different generators: one for each folder\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255) # rescaling input\n",
        "\n",
        "train_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"train/\", \n",
        "                                          target_size=(SIZE, SIZE), \n",
        "                                          class_mode=None)\n",
        "valid_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"val/\", \n",
        "                                          target_size=(SIZE, SIZE), \n",
        "                                          class_mode=None)\n",
        "test_gen = datagen.flow_from_directory(path+\"download/\"+dataset+\"test/\", \n",
        "                                          target_size=(SIZE, SIZE), \n",
        "                                          class_mode=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCbMGw2v1bjG"
      },
      "source": [
        "# Convert from RGB to Lab space\n",
        "def convert_dataset(gen):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in tqdm(range(len(gen))):\n",
        "        for img in gen[i]:\n",
        "            lab = rgb2lab(img)\n",
        "            X.append(lab[:,:,0])\n",
        "            Y.append(lab[:,:,1:] / 128) # --> new range [-1,1]\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    X = X.reshape(X.shape+(1,))\n",
        "    print(X.shape, Y.shape)\n",
        "    return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJtQVAr91fz0"
      },
      "source": [
        "X_train,Y_train = convert_dataset(train_gen)\n",
        "X_valid,Y_valid = convert_dataset(valid_gen)\n",
        "X_test,Y_test = convert_dataset(test_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkYT1pd01h65"
      },
      "source": [
        "np.save('./preprocessed/'+dataset+'x_train.npy', X_train)\n",
        "np.save('./preprocessed/'+dataset+'y_train.npy', Y_train)\n",
        "\n",
        "np.save('./preprocessed/'+dataset+'x_valid.npy', X_valid)\n",
        "np.save('./preprocessed/'+dataset+'y_valid.npy', Y_valid)\n",
        "\n",
        "np.save('./preprocessed/'+dataset+'x_test.npy', X_test)\n",
        "np.save('./preprocessed/'+dataset+'y_test.npy', Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}